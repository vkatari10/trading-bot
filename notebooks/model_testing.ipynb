{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c039b5-fe0f-42a3-9a20-4dc23aa537ab",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "For this project determining which strategies to use determines the sucess of the trading bot.<br>\n",
    "In the context of this project we follow this structure in 3 steps found in these folders in `src/`<br>\n",
    "`backtesting/` -> `data/` -> `models/`<br>\n",
    "1. `backtesting/` - Here we try out any choice of strategies we want to try using `backtrader` to find a viable technical indicator based approach to ensure that historically our selection would turn a profit.\n",
    "2. `data/` - Here we then implement those technical indicators onto a `DataFrame` from historical data on a stock of our choice. This also includes the signals to indicate that we should buy or sell, this makes the `DataFrame` contain all the features and labels necessary to train model on.\n",
    "3. `models/` - Here we train the machine learning models on the modified `DataFrame`s and validate that they can then accurately predict the buy and sell signals based on technical indicators<br>\n",
    "Given this pipeline we can ensure the validity of the technical indicators and allow machine learning models to train on them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66fc09-bfba-4361-b415-381fd8f2b847",
   "metadata": {},
   "source": [
    "# Backtesting\n",
    "We first test the strategy on historical data using technicals of our choice using `backtrader`, once we decide what technicals indicators we would like to use we then apply them in the `process_data()` method found in `src/data/data_processing.py`. After we define the modifications to the `DataFrame` then we can start training the ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cc07808-696f-4691-9ee8-24264b47199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data import data_processing as dp # to get modified DataFrames with Technicals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b303349-364c-4f78-a943-1a41258c068b",
   "metadata": {},
   "source": [
    "# Get DataFrame\n",
    "In `src/data/data_processing.py` we can load a `DataFrame` that contains our own technical indicators using the `get_df` method and a spcecified ticker. We can modify the strategy and technical indicators in the `process_data` method to adjust to new strategies. This method will also add the signals to the df to allow ML models to train on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea81fc3-9241-4005-a7b4-d8dc89daa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dp.get_df(\"AAPL\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d96ea3-1259-42c6-ae7e-ce0faf5aa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add signals\n",
    "df['ACTION'] = df.iloc[:, 12] + df.iloc[:, 13] + df.iloc[:, 14] + df.iloc[:, 15] + df.iloc[:, 16]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc2505-e0cb-43d0-bc83-78199987d7fd",
   "metadata": {},
   "source": [
    "# Construct ML model\n",
    "Once we have a dataframe with the technical indicators we would like to use, we can construct the ML model. We will use scikit-learn to simplify the process. Here we will scale the data, set up the pipeline, and split the data up. However most of the signals in the `DataFrame` are just \"HOLD\" so we need to do a lot preprocessing in regards to filling in those gaps so the ML can have more diverse labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5c44b-006c-40f5-9f70-c3868a8026ba",
   "metadata": {},
   "source": [
    "# Train ML Model\n",
    "We will test the model on the training data which will be a chunk of the dataframe we got from yfinance. Then once trained we can put it another chunk for validation data and adjust parameters as needed. Finally we can run the model on the test data for final analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c77a96c-fc49-48e6-9dd2-eebab8d46339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00        18\n",
      "          -1       0.82      0.81      0.82       629\n",
      "           0       0.84      0.93      0.88      1356\n",
      "           1       0.61      0.26      0.37       193\n",
      "           2       0.65      0.45      0.53        38\n",
      "\n",
      "    accuracy                           0.82      2234\n",
      "   macro avg       0.59      0.49      0.52      2234\n",
      "weighted avg       0.81      0.82      0.81      2234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "\n",
    "X = df.iloc[:, [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11]] # All columns except the signal (feature)\n",
    "y = df.iloc[:, -1] # Just the signal column (label)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42) \n",
    "X_res, y_res = rus.fit_resample(X, y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb134a7c-4777-467b-9a32-e6dfa6e5ee73",
   "metadata": {},
   "source": [
    "# Export Model \n",
    "Once the model is trained we can export it using the `pickle` library or another equivalent. We can then use this in a driver where we can then feed the bot live data from the `finnhub` API and then recompute the technicals used to train the bot and allow it to decide and execute trades through the Alpaca API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e213dfe2-da83-4638-9209-62bfc9fd29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = \"../src/models/model_v1.pkl\"\n",
    "pickle.dump(rf_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f9011-7f33-412e-a02e-e123ac969acc",
   "metadata": {},
   "source": [
    "# Test model on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "878845b0-ed1f-4e51-9d35-49c31a4622e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.iloc[:, [0,1, 2, 3, 5, 6, 7, 8, 9, 10, 11, -1]]\n",
    "new_df.to_csv('../src/engine/refined_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "704dcc70-e2aa-40f9-9f2f-104e8f110cdf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0377acd-69b1-40f4-bb7a-a4ba1c3414e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
